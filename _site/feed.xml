<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-01-03T23:14:22+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">JSC’s DevLog</title><subtitle>SE and AI version 1.0</subtitle><author><name>JSC</name><email>newwin0198@handong.ac.kr</email></author><entry><title type="html">2023-HGU-ML Lecture 7. Clustering</title><link href="http://localhost:4000/recent/Clustering/" rel="alternate" type="text/html" title="2023-HGU-ML Lecture 7. Clustering" /><published>2024-01-03T00:00:00+09:00</published><updated>2024-01-03T00:00:00+09:00</updated><id>http://localhost:4000/recent/Clustering</id><content type="html" xml:base="http://localhost:4000/recent/Clustering/"><![CDATA[<h1 id="clustering">Clustering</h1>

<ul>
  <li>unsupervised learning
    <ul>
      <li>density estimation</li>
      <li>clustering</li>
      <li>dimension reduction</li>
      <li>factor analysis</li>
      <li>representation learning</li>
    </ul>
  </li>
  <li>Clustering helps us understand the data samples
    <ul>
      <li>clustering → grouping samples in a way that samples in the same group are more similar to each other than to those in another group</li>
    </ul>
  </li>
  <li>Approaches for clustering
    <ul>
      <li>Connectivity based</li>
      <li>Centroids based</li>
      <li>distribution based</li>
      <li>graph theoretic</li>
    </ul>
  </li>
  <li>hierarchical clustering
    <ul>
      <li>dendrogram in hierarchical clustering</li>
      <li>bottom-up/top-down manner
        <ul>
          <li>agglomerative (bottom-up)
            <ul>
              <li>at each step, compute distances between all pairs of clusters, then merge the ones with the smallest distance.
                <ul>
                  <li>distance between centroids</li>
                  <li>distance between the two closest or furthest points</li>
                  <li>define the number of clusters</li>
                  <li>use cohesion</li>
                </ul>
              </li>
            </ul>
          </li>
          <li>divisive (top-down)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>K-means
    <ul>
      <li>an unsupervised clustering algorithm</li>
      <li>K → number of clusters</li>
      <li>global convergence</li>
      <li>only a local minimum is obtained</li>
      <li>sensitive to initialization</li>
      <li>sensitive to outliers</li>
      <li>Algorithm
        <ul>
          <li>each vector will be assigned to one cluster exclusively</li>
          <li>define dissimilarity measures such as Euclidean distance</li>
          <li>K-means minimizes within cluster point scatter</li>
          <li>It is an optimization problem</li>
        </ul>

        <p><img src="../../../assets/ML/Clus/Untitled.png" /></p>
      </li>
      <li>Issues
        <ul>
          <li>initialization is important</li>
          <li>distance function (or metric) should be carefully chosen</li>
          <li>K-means is sensitive to outliers</li>
          <li>kMedoids → using medoids (one of the actual points)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>mixture of Gaussian
    <ul>
      <li>a distribution can be approximated by a weighted sum of component Gaussian densities with parameters</li>
    </ul>

    <p><img src="../../../assets/ML/Clus/Untitled 1.png" /></p>

    <ul>
      <li>latent variables</li>
    </ul>

    <p><img src="../../../assets/ML/Clus/Untitled 2.png" /></p>

    <ul>
      <li>Gaussian densities with MLE</li>
    </ul>
  </li>
  <li>expectation maximization (EM)
    <ol>
      <li>The Expectation-Maximization algorithm is the algorithm to find the maximum likelihood or maximum a posteriori estimates of parameters in probabilistic models. It repeatedly applies the expectation step and the maximization steps.</li>
      <li>In the expectation step, calculate the expected value of log-likelihood using the estimated value of a parameter. Particularly when dealing with incomplete or missing data, the expectation step involves calculating the posterior probability distribution of the missing data given the observed data and the current parameter estimates.</li>
      <li>The maximization step is finding a variable value that maximizes this expected value. The variable value calculated in the maximization step is used as the estimated value of the next expectation step.</li>
      <li>The process iterates between the E and M steps until convergence, where the parameter estimates stabilize. Using this algorithm, you can easily know one of the parameters or latent variables, when you know the other values.
        <ul>
          <li>an iterative optimization method to estimate parameters, given measurements X when there are hidden (nuisance) variables Z</li>
          <li>it can maximize the posterior probability (or likelihood or joint probability)</li>
          <li>a naive approach would be an alternate optimization between Z and estimate parameters</li>
          <li>EM: lower bound</li>
        </ul>
        <ul>
          <li><a href="http://norman3.github.io/prml/docs/chapter09/4.html">http://norman3.github.io/prml/docs/chapter09/4.html</a></li>
          <li><a href="https://zzaebok.github.io/machine_learning/EM_algorithm/">https://zzaebok.github.io/machine_learning/EM_algorithm/</a></li>
          <li>E steps
            <ul>
              <li>suppose that we try to maximize joint probability, lower bound B</li>
              <li>should tight log P(X, theta) → B should be maximized with respect to ft(Z)</li>
            </ul>
          </li>
          <li>
            <p>M steps</p>

            <p><img src="../../../assets/ML/Clus/Untitled 3.png" /></p>
          </li>
        </ul>
      </li>
    </ol>

    <p><img src="../../../assets/ML/Clus/Untitled 4.png" /></p>
  </li>
  <li>
    <p>MoG training with EM</p>

    <p><img src="../../../assets/ML/Clus/Untitled 5.png" /></p>
  </li>
  <li>Difference between MoG and K-means
    <ul>
      <li>EM for mixtures of Gaussians is just like a soft version of K-means, with
  fixed priors and covariance</li>
      <li>Instead of hard assignments in the E-step, we do soft assignments based on
  the softmax of the squared Mahalanobis distance from each point to each
  cluster.</li>
      <li>Each center is moved by weighted means of the data, with weights given by
  soft assignments</li>
      <li>In K-means, weights are 0 or 1</li>
    </ul>
  </li>
  <li>Spectral clustering
    <ul>
      <li>graphs:
        <ul>
          <li>natural way to represent many types of data</li>
          <li>nodes corresponding to data samples</li>
          <li>edges connecting the nodes</li>
        </ul>
      </li>
      <li>graph partitioning
        <ul>
          <li>graph cut
            <ul>
              <li>consider a partition of the graph into two parts A and B</li>
            </ul>
          </li>
          <li>normalized cut
            <ul>
              <li>considers the connectivity with the volume of each group</li>
            </ul>
          </li>
          <li>normalized cut derivation</li>
        </ul>

        <p><img src="../../../assets/ML/Clus/Untitled 6.png" /></p>
      </li>
      <li>competitive learning
        <ul>
          <li>a clustering algorithm related to humans based on neural network</li>
        </ul>
      </li>
      <li>when the number of clusters is unknown
        <ul>
          <li>DBSCAN (Density-based spatial clustering of applications with noise)</li>
        </ul>

        <p><img src="../../../assets/ML/Clus/Untitled 7.png" /></p>
      </li>
    </ul>
  </li>
</ul>]]></content><author><name>JSC</name><email>newwin0198@handong.ac.kr</email></author><category term="ML" /><category term="ML" /><summary type="html"><![CDATA[Clustering by Prof. Henry Choi]]></summary></entry><entry><title type="html">2023-HGU-ML Lecture 6. Decision Theory</title><link href="http://localhost:4000/recent/Decision_Theory/" rel="alternate" type="text/html" title="2023-HGU-ML Lecture 6. Decision Theory" /><published>2023-12-28T00:00:00+09:00</published><updated>2023-12-28T00:00:00+09:00</updated><id>http://localhost:4000/recent/Decision_Theory</id><content type="html" xml:base="http://localhost:4000/recent/Decision_Theory/"><![CDATA[<h1 id="decision-theory">Decision Theory</h1>

<ul>
  <li>given an input vector, our goal is to predict a corresponding target value
    <ul>
      <li>The target value is described probabilistically</li>
    </ul>
  </li>
  <li>DT provides optimal decisions in situations involving uncertainty, combined with probability theory</li>
  <li>Three approaches to making a decision
    <ul>
      <li>generative model, \(p(t, x)\) or \(p(x \mid t)\)
        <ul>
          <li>can be used for the classification using \(p(t \mid x)\) =  \(\frac { p(x \mid t)p(t) }{p(x)}\)</li>
          <li>generate new data or detect outliers</li>
        </ul>
      </li>
      <li>Discriminative Model
        <ul>
          <li>\(p(t \mid x)\), just classficiation</li>
        </ul>
      </li>
      <li>Discriminant function
        <ul>
          <li>f(x), model a map function from input x to a label t</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>probability models for decision
    <ul>
      <li>misclassification rate vs. loss function</li>
    </ul>

    <p><img src="../../../assets/ML/DecTheo/Untitled.png" /></p>
  </li>
  <li>
    <p>Type 1 and 2 error</p>

    <p><img src="../../../assets/ML/DecTheo/Untitled 1.png" /></p>
  </li>
  <li>
    <p>receiver operating characteristics (ROC)</p>

    <p><img src="../../../assets/ML/DecTheo/Untitled 2.png" /></p>
  </li>
  <li>loss function
    <ul>
      <li>a function that maps an event onto a “cost” value</li>
    </ul>
  </li>
  <li>minimum expected loss
    <ul>
      <li>our goal is to minimize an expected loss (or risk)</li>
      <li>classify x into class which minimizes the conditional risk (or expected loss)</li>
    </ul>
  </li>
  <li>
    <p>loss functions in general</p>

    <p><img src="../../../assets/ML/DecTheo/Untitled 3.png" /></p>
  </li>
  <li>The term “probability” refers to the possibility of something happening. The term Likelihood refers to the process of determining the best data distribution given a specific situation in the data. When calculating the probability of a given outcome, you assume the model’s parameters are reliable.</li>
  <li>Three decision rules based on probability
    <ul>
      <li>Maximum Likelihood
        <ul>
          <li><a href="https://angeloyeo.github.io/2020/07/17/MLE.html">https://angeloyeo.github.io/2020/07/17/MLE.html</a></li>
        </ul>
      </li>
      <li>Maximum a posterior
        <ul>
          <li><a href="https://process-mining.tistory.com/126">https://process-mining.tistory.com/126</a></li>
          <li><a href="https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation">https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation</a></li>
        </ul>
      </li>
      <li>Bayes Risk
        <ul>
          <li><a href="http://www.stat.yale.edu/~yw562/teaching/598/lec02.pdf">http://www.stat.yale.edu/~yw562/teaching/598/lec02.pdf</a></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>Bayes Risk is a concept in decision theory that measures the expected loss associated with a decision, taking into account the uncertainty in the underlying parameters or states. It is derived from Bayesian decision theory, which combines prior knowledge with observed data to make optimal decisions.</p>

<p>In the context of decision theory, the Bayes Risk \((R(\delta))\) associated with a decision rule \((\delta)\) is defined as the expected value of the loss function under the posterior distribution of the parameters, given the observed data. Mathematically, it can be expressed as:</p>

\[R(\delta) = \int L(\theta, \delta(x)) \cdot f(\theta | x) \, d\theta\]

<p>where:</p>

<ul>
  <li>\(L(\theta, \delta(x))\) is the loss function, representing the cost associated with making a decision \(\delta(x)\) when the true state is \(\theta\).</li>
  <li>\(f(\theta \mid x)\) is the posterior distribution of the parameters given the observed data \((x)\) .</li>
</ul>

<p>The Bayes Risk accounts for the uncertainty in parameter estimation by integrating the loss over the entire parameter space, weighted by the posterior distribution. This approach reflects the Bayesian philosophy of updating beliefs based on both prior knowledge and observed evidence.</p>

<p>In practice, the decision rule \((\delta)\) can be chosen to minimize the Bayes Risk, resulting in a decision that is optimal in terms of expected loss. The Bayes Risk provides a comprehensive measure of the cost associated with decisions, considering the uncertainty inherent in parameter estimation in a Bayesian framework.</p>

<p>Maximum Likelihood Estimation (MLE) and Maximum A Posteriori (MAP) estimation are both methods used to estimate the parameters of a statistical model, but they differ in their underlying principles and assumptions.</p>

<p><strong>Maximum Likelihood Estimation (MLE):</strong></p>

<ol>
  <li><strong>Objective:</strong> MLE aims to find the values of the model parameters that maximize the likelihood function, which measures how well the observed data is explained by the model.</li>
  <li><strong>Assumption:</strong> MLE assumes a uniform or non-informative prior distribution, meaning that all parameter values are equally likely before observing the data.</li>
  <li>
    <p><strong>Formula:</strong> \(\hat{\theta}_{\text{MLE}} = \arg\max_{\theta} \mathcal{L}(\theta \mid \text{data}),\) where $\mathcal{L}(\theta \mid \text{data})$ is the likelihood function.</p>
  </li>
  <li><strong>Result:</strong> MLE provides a point estimate of the parameters that maximizes the likelihood of the observed data.</li>
</ol>

<p><strong>Maximum A Posteriori (MAP) Estimation:</strong></p>

<ol>
  <li><strong>Objective:</strong> MAP estimation combines the likelihood function with a prior distribution to find the values of the parameters that maximize the posterior distribution.</li>
  <li><strong>Assumption:</strong> MAP incorporates prior knowledge or beliefs about the parameters by introducing a prior distribution. This prior reflects any information available before observing the data.</li>
  <li><strong>Formula:</strong> \(\hat{\theta}_{\text{MAP}} = \arg\max_{\theta} P(\theta \mid \text{data}),\) where $P(\theta \mid \text{data})$ is the posterior distribution.</li>
  <li><strong>Result:</strong> MAP provides a point estimate of the parameters that maximizes the posterior distribution, considering both the likelihood and the prior.</li>
</ol>

<p><strong>Key Differences:</strong></p>

<ul>
  <li><strong>Incorporating Prior Information:</strong> The major distinction lies in the incorporation of prior information. MLE assumes a non-informative prior (flat prior), while MAP explicitly considers a prior distribution that may encode prior beliefs or knowledge about the parameters.</li>
  <li><strong>Formula:</strong> The formulas for MLE and MAP are similar, but MAP includes the prior term in the optimization process, affecting the final estimate.</li>
  <li><strong>Robustness:</strong> MAP estimates may be more robust when dealing with limited data because the prior helps regularize the estimation. MLE can be sensitive to sparse or noisy data.</li>
</ul>

<p>In summary, MLE and MAP are both methods for estimating parameters, with MLE relying solely on the likelihood function and MAP incorporating prior information through a prior distribution. The choice between them depends on the available information and the desired balance between data-driven estimates and prior beliefs.</p>

<ul>
  <li>
    <p>discriminant function g(x) using gi(x) (e.g., ML, MAP, Bayes risk)</p>

    <p><img src="../../../assets/ML/DecTheo/Untitled 4.png" /></p>
  </li>
  <li>
    <p>decision boundary</p>

    <p><img src="../../../assets/ML/DecTheo/Untitled 5.png" /></p>

    <ul>
      <li>boundaries for Gaussian
        <ul>
          <li>case1: features are uncorrelated (i.e., independent) with the same variance</li>
          <li>case2: the classes have identical covariance matrices</li>
          <li>case3: each class has a different covariance matrix</li>
        </ul>
      </li>
      <li><a href="https://www.cs.cmu.edu/~aarti/Class/10315_Fall19/lecs/Lecture3.pdf">https://www.cs.cmu.edu/~aarti/Class/10315_Fall19/lecs/Lecture3.pdf</a></li>
    </ul>
  </li>
</ul>]]></content><author><name>JSC</name><email>newwin0198@handong.ac.kr</email></author><category term="ML" /><category term="ML" /><summary type="html"><![CDATA[Decision... by Prof. Henry Choi]]></summary></entry><entry><title type="html">2023-HGU-ML Lecture 5. Density Estimation</title><link href="http://localhost:4000/recent/Density_Estimation/" rel="alternate" type="text/html" title="2023-HGU-ML Lecture 5. Density Estimation" /><published>2023-12-27T00:00:00+09:00</published><updated>2023-12-27T00:00:00+09:00</updated><id>http://localhost:4000/recent/Density_Estimation</id><content type="html" xml:base="http://localhost:4000/recent/Density_Estimation/"><![CDATA[<h1 id="density-estimation">Density Estimation</h1>

<ul>
  <li>for a data sample, we need a vector to represent</li>
  <li>for a dataset with many samples, we need the distribution of the samples to understand the dataset</li>
  <li>Density Estimation
    <ul>
      <li>estimation of an underlying probability density function p(x) based on observed data</li>
      <li>we can understand the population (unsupervised)</li>
      <li>the density can be used for classification</li>
      <li>parametric methods
        <ul>
          <li>assuming a functional form about the distribution (e.g., Gaussian)</li>
          <li>estimating the parameters (e.g., mean and variance)</li>
        </ul>
      </li>
      <li>non-parametric methods
        <ul>
          <li>no assumption on the distribution</li>
          <li>estimating the density directly from data</li>
        </ul>
      </li>
      <li>semi-parametric methods
        <ul>
          <li>a very general class of functional forms</li>
          <li>with more parameters than parametric methods</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>estimation theory
    <ul>
      <li>estimating the unknown parameters from data</li>
      <li>bias
        <ul>
          <li>error from assumptions in the learning algorithm</li>
          <li>underfitting</li>
        </ul>
      </li>
      <li>variance
        <ul>
          <li>error from sensitivity to small fluctuations in the data</li>
          <li>overfitting</li>
        </ul>
      </li>
      <li>bias-variance trade-off</li>
    </ul>
  </li>
  <li>maximum likelihood estimation (MLE)
    <ul>
      <li>a method of estimating the parameters of a distribution
        <ul>
          <li>by maximizing a likelihood function</li>
          <li>the observed data will be most probable</li>
        </ul>
      </li>
      <li>maximum likelihood estimate
        <ul>
          <li>estimated parameter maximizing the likelihood function</li>
        </ul>
      </li>
      <li><a href="https://angeloyeo.github.io/2020/07/17/MLE.html">https://angeloyeo.github.io/2020/07/17/MLE.html</a></li>
    </ul>
  </li>
  <li>likelihood of Gaussian distribution
    <ul>
      <li>how likely is the data to occur given the parameters</li>
    </ul>
  </li>
  <li>log-likelihood
    <ul>
      <li>the log function is monotonic and makes the likelihood equation much simpler</li>
    </ul>
  </li>
  <li>
    <p>MLE for Gaussian</p>

    <p><img src="../../../assets/ML/DensityEst/Untitled.png" /></p>

    <p><img src="../../../assets/ML/DensityEst/Untitled 1.png" /></p>
  </li>
  <li>the mean estimator is unbiased, but the variance estimator is biased
    <ul>
      <li>maximum likelihood estimator is related to overfitting</li>
    </ul>

    <p><img src="../../../assets/ML/DensityEst/Untitled 2.png" /></p>
  </li>
  <li>histogram as a nonparametric method
    <ul>
      <li>probability of x in a bin</li>
    </ul>

    <p><img src="../../../assets/ML/DensityEst/Untitled 3.png" /></p>
  </li>
  <li>KDE and kNN
    <ul>
      <li>kernel density estimation (KDE)
        <ul>
          <li><a href="https://seongkyun.github.io/study/2019/02/03/KDE/">https://seongkyun.github.io/study/2019/02/03/KDE/</a></li>
          <li><a href="https://darkpgmr.tistory.com/147">https://darkpgmr.tistory.com/147</a></li>
          <li>Parzen window</li>
        </ul>

        <p><img src="../../../assets/ML/DensityEst/Untitled 4.png" /></p>
      </li>
      <li>k nearest neighbors (kNN)
        <ul>
          <li>fix k, and increase V to include k samples</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Semi-parametric method
    <ul>
      <li>Mixture of Gaussian</li>
    </ul>

    <p><img src="../../../assets/ML/DensityEst/Untitled 5.png" /></p>

    <p><img src="../../../assets/ML/DensityEst/Untitled 6.png" /></p>
  </li>
</ul>]]></content><author><name>JSC</name><email>newwin0198@handong.ac.kr</email></author><category term="ML" /><category term="ML" /><summary type="html"><![CDATA[Density Estimation by Prof. Henry Choi]]></summary></entry><entry><title type="html">2023-HGU-ML Lecture 4. Information Theory</title><link href="http://localhost:4000/recent/Information_Theory/" rel="alternate" type="text/html" title="2023-HGU-ML Lecture 4. Information Theory" /><published>2023-12-18T00:00:00+09:00</published><updated>2023-12-18T00:00:00+09:00</updated><id>http://localhost:4000/recent/Information_Theory</id><content type="html" xml:base="http://localhost:4000/recent/Information_Theory/"><![CDATA[<h1 id="information-theory">Information Theory</h1>

<ul>
  <li>entropy
    <ul>
      <li>unpredictability of information content
        <ul>
          <li>it captures the value of surprises</li>
          <li>information from independent events is “additive”</li>
          <li>information is non-negative</li>
        </ul>
      </li>
    </ul>

    <p><img src="../../../assets/ML/InfoTheo/Untitled.png" /></p>

    <ul>
      <li>as distributions become more uniform, entropy goes up.</li>
      <li>Gaussian distribution has the maximum entropy among possible distributions on an infinite range with a finite mean and variance</li>
    </ul>

    <p><img src="../../../assets/ML/InfoTheo/Untitled 1.png" /></p>

    <ul>
      <li>Kullback Leibler (KL) divergence
        <ul>
          <li><a href="https://hyunw.kim/blog/2017/10/27/KL_divergence.html">https://hyunw.kim/blog/2017/10/27/KL_divergence.html</a></li>
          <li><a href="https://hwiyong.tistory.com/408">https://hwiyong.tistory.com/408</a></li>
          <li>divergence between two probability distributions</li>
        </ul>
      </li>
    </ul>

    <p><img src="../../../assets/ML/InfoTheo/Untitled 2.png" /></p>

    <p>Entropy is a measure of uncertainty or disorder in a set of outcomes or information. In information theory, three related concepts are often used: marginal entropy, joint entropy, and conditional entropy.</p>

    <ol>
      <li><strong>Marginal Entropy:</strong>
        <ul>
          <li><strong>Definition:</strong> Marginal entropy quantifies the uncertainty associated with a single random variable in isolation, without considering any other variables.</li>
          <li><strong>Formula:</strong> For a discrete random variable \((X)\), the marginal entropy \((H(X))\) is calculated as \((H(X) = -\sum_{x} P(x) \log_2(P(x)))\), where \((P(x))\) is the probability of each possible outcome of \((X)\).</li>
          <li><strong>Interpretation:</strong> A higher marginal entropy indicates greater uncertainty or randomness associated with the individual variable.</li>
        </ul>
      </li>
      <li><strong>Joint Entropy:</strong>
        <ul>
          <li><strong>Definition:</strong> Joint entropy measures the uncertainty associated with a pair of random variables considered together.</li>
          <li><strong>Formula:</strong> For two discrete random variables \((X)\) and \((Y)\), the joint entropy \((H(X, Y))\) is calculated as \((H(X, Y) = -\sum_{x, y} P(x, y) \log_2(P(x, y)))\), where \((P(x, y))\) is the joint probability of the outcomes \(((x, y))\).</li>
          <li><strong>Interpretation:</strong> Joint entropy provides a measure of uncertainty when considering the combined outcomes of two variables.</li>
        </ul>
      </li>
      <li><strong>Conditional Entropy:</strong>
        <ul>
          <li><strong>Definition:</strong> Conditional entropy quantifies the remaining uncertainty in one random variable given the knowledge of another.</li>
          <li><strong>Formula:</strong> For two discrete random variables \((X)\) and \((Y)\), the conditional entropy \((H(X \mid Y))\) is calculated as \((H(X \mid Y) = -\sum_{x, y} P(x, y) \log_2\left(\frac{P(x, y)}{P(y)}\right))\), where \((P(x, y))\) is the joint probability, (P(y)) is the marginal probability of (Y), and the sum is taken over all possible outcomes of \((X)\) and \((Y)\).</li>
          <li><strong>Interpretation:</strong> Conditional entropy reflects the remaining uncertainty in \((X)\) when \((Y)\) is known. A lower conditional entropy indicates that knowledge of \((Y)\) reduces the uncertainty about \((X)\).</li>
        </ul>
      </li>
    </ol>

    <p>In summary, marginal entropy captures the uncertainty of individual variables, joint entropy quantifies the uncertainty of multiple variables considered together, and conditional entropy measures the remaining uncertainty in one variable given the knowledge of another. These concepts are fundamental in understanding and analyzing the information content and relationships between random variables in various domains, including information theory, statistics, and machine learning.</p>

    <ul>
      <li>KL divergence is not symmetric</li>
      <li><a href="https://math.stackexchange.com/questions/1972633/what-is-the-difference-between-moment-projection-and-information-projection">https://math.stackexchange.com/questions/1972633/what-is-the-difference-between-moment-projection-and-information-projection</a></li>
    </ul>
  </li>
  <li>mutual information
    <ul>
      <li>measures how much information is shared</li>
      <li>the more independent they are, the smaller MI is</li>
    </ul>
  </li>
  <li>Cross Entropy
    <ul>
      <li>it measures dissimilarity between and a target</li>
      <li>identical to KL up to an additive constant</li>
      <li>popular loss function</li>
      <li><a href="https://velog.io/@rcchun/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%ED%81%AC%EB%A1%9C%EC%8A%A4-%EC%97%94%ED%8A%B8%EB%A1%9C%ED%94%BCcross-entropy">https://velog.io/@rcchun/머신러닝-크로스-엔트로피cross-entropy</a></li>
    </ul>
  </li>
  <li>causality - information flow</li>
  <li>
    <p>transfer entropy</p>

    <p><img src="../../../assets/ML/InfoTheo/Untitled 3.png" /></p>
  </li>
</ul>]]></content><author><name>JSC</name><email>newwin0198@handong.ac.kr</email></author><category term="ML" /><category term="ML" /><summary type="html"><![CDATA[Information Theory by Prof. Henry Choi]]></summary></entry><entry><title type="html">2023-HGU-ML Lecture 3. Probability and Statistics for ML</title><link href="http://localhost:4000/recent/Probability_and_Statistics/" rel="alternate" type="text/html" title="2023-HGU-ML Lecture 3. Probability and Statistics for ML" /><published>2023-12-17T00:00:00+09:00</published><updated>2023-12-17T00:00:00+09:00</updated><id>http://localhost:4000/recent/Probability_and_Statistics</id><content type="html" xml:base="http://localhost:4000/recent/Probability_and_Statistics/"><![CDATA[<h1 id="probability-and-statistics-for-ml">Probability and Statistics for ML</h1>

<ul>
  <li>Probability
    <ul>
      <li>IID: independent identically distributed</li>
      <li>Simpson’s Paradox</li>
      <li>Probability is a number assigned to an event indicating “how likely” the event will occur when randomly selected</li>
      <li>uncertainty can make the model simpler. A simple/uncertain model rather than a complex/certain one, even when modeling the true/deterministic rule is possible</li>
      <li>mathematical probability measures the likelihood that events will occur</li>
      <li>empirical statistics is science of collecting and analyzing numerical data in large quantities</li>
      <li>Random Variable
        <ul>
          <li>a variable whose possible values are numerical outcomes of a random phenomenon</li>
          <li>is a measurable function from a set of possible outcomes to a measurable space</li>
        </ul>
      </li>
    </ul>

    <p><img src="../../../assets/ML/ProbAndStats/Untitled.png" /></p>

    <p><img src="../../../assets/ML/ProbAndStats/Untitled 1.png" /></p>

    <ul>
      <li>marginal, joint, and conditional probabilities</li>
    </ul>

    <p><img src="../../../assets/ML/ProbAndStats/Untitled 2.png" /></p>

    <p><img src="../../../assets/ML/ProbAndStats/Untitled 3.png" /></p>

    <p><img src="../../../assets/ML/ProbAndStats/Untitled 4.png" /></p>

    <ul>
      <li>Bayes rule presents the transformation process of our beliefs.
        <ul>
          <li>subjective belief on Y changes with X</li>
        </ul>
      </li>
      <li>learning is
        <ul>
          <li>nothing but to update our confidence from prior to posterior.</li>
          <li>the key factor is likelihood which is based on data.</li>
        </ul>
      </li>
      <li>
        <p>Bayesianism (Thomas Bayes) vs. frequentism (Ronald A. Fisher)</p>

        <p>Bayesianism and frequentism are two distinct approaches to statistical inference, and they differ in their fundamental principles and interpretations of probability. Thomas Bayes and Ronald A. Fisher were prominent figures associated with these respective approaches.</p>

        <p>Bayesianism (Thomas Bayes):</p>

        <ol>
          <li><strong>Probability as Belief:</strong>
            <ul>
              <li>In Bayesian statistics, probability is interpreted as a measure of belief or confidence in a particular hypothesis. It reflects the degree of certainty or uncertainty given available information.</li>
              <li>Bayesians start with a prior probability distribution, representing initial beliefs about a hypothesis before observing data.</li>
            </ul>
          </li>
          <li><strong>Bayes’ Theorem:</strong>
            <ul>
              <li>The cornerstone of Bayesian statistics is Bayes’ theorem, which updates the prior belief based on observed data to obtain a posterior probability distribution.</li>
              <li>Bayes’ theorem relates the posterior probability (probability of the hypothesis given the data) to the prior probability and the likelihood of the data given the hypothesis.</li>
            </ul>

\[P(H|D) = \frac{P(D|H) \cdot P(H)}{P(D)}\]

            <ul>
              <li>\(P(H|D)\) is the posterior probability, 
 \(( P(D|H) )\) is the likelihood, 
 \(( P(H) )\) is the prior probability, and 
 \(( P(D) )\) is the probability of the data.</li>
            </ul>
          </li>
          <li><strong>Incorporation of Prior Knowledge:</strong>
            <ul>
              <li>Bayesian analysis allows the incorporation of prior knowledge into the analysis, enabling the adjustment of beliefs based on both prior information and new data.</li>
            </ul>
          </li>
        </ol>

        <p>Frequentism (Ronald A. Fisher):</p>

        <ol>
          <li><strong>Probability as Frequency:</strong>
            <ul>
              <li>Frequentist statistics, on the other hand, views probability as a long-run frequency or limit of relative frequencies. Probability is associated with the repeated occurrence of events in a hypothetical infinite sequence of trials.</li>
            </ul>
          </li>
          <li><strong>No Prior Probability:</strong>
            <ul>
              <li>Unlike Bayesianism, frequentist statistics does not involve prior probabilities. It relies solely on observed data and the likelihood of obtaining that data under different hypotheses.</li>
            </ul>
          </li>
          <li><strong>Hypothesis Testing and Confidence Intervals:</strong>
            <ul>
              <li>Frequentist methods often focus on hypothesis testing and confidence intervals. Hypothesis testing involves assessing the evidence against a null hypothesis, and confidence intervals provide a range of plausible values for an unknown parameter.</li>
            </ul>
          </li>
          <li><strong>Objective and Reproducible:</strong>
            <ul>
              <li>Frequentist methods are considered more objective and reproducible, as they do not rely on subjective prior beliefs.</li>
            </ul>
          </li>
        </ol>

        <p>Comparison:</p>

        <ul>
          <li><strong>Subjectivity:</strong>
            <ul>
              <li>Bayesianism is often criticized for being subjective due to the reliance on prior beliefs. Frequentism is considered more objective since it doesn’t involve prior probabilities.</li>
            </ul>
          </li>
          <li><strong>Flexibility vs. Objectivity:</strong>
            <ul>
              <li>Bayesian methods provide a flexible framework for incorporating prior information, but this flexibility is seen by some as a weakness. Frequentism, being more rigid, is valued for its objectivity and reproducibility.</li>
            </ul>
          </li>
          <li><strong>Interpretation of Probability:</strong>
            <ul>
              <li>Bayesianism interprets probability as a measure of belief, while frequentism interprets it as a long-term frequency.</li>
            </ul>
          </li>
        </ul>

        <p>Both Bayesian and frequentist approaches have their strengths and weaknesses, and the choice between them often depends on the nature of the problem, available data, and the philosophical stance of the statistician or researcher. In practice, researchers sometimes use a combination of both approaches, known as Bayesian-frequentist synthesis.</p>

        <ul>
          <li>parameters
            <ul>
              <li>updated (represented probabilistically) vs. fixed</li>
              <li>with prior vs. no prior</li>
            </ul>
          </li>
          <li>data
            <ul>
              <li>fixed vs. random samples</li>
            </ul>
          </li>
          <li>example
            <ul>
              <li>diagnosis vs. dice</li>
            </ul>
          </li>
          <li>focused on
            <ul>
              <li>posterior vs likelihood</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>

    <p><img src="../../../assets/ML/ProbAndStats/Untitled 5.png" /></p>

    <ul>
      <li>conjugate distributions
        <ul>
          <li><a href="https://en.wikipedia.org/wiki/Conjugate_prior">https://en.wikipedia.org/wiki/Conjugate_prior</a></li>
          <li>Prior and posterior distribution is in the same family</li>
        </ul>
      </li>
      <li>Central Limit Theorem</li>
      <li>Cramer’s theorem
        <ul>
          <li><a href="https://carstart.tistory.com/160">https://carstart.tistory.com/160</a></li>
        </ul>
      </li>
      <li>multivariate Gaussian
        <ul>
          <li><a href="https://dhpark1212.tistory.com/entry/%EB%8B%A4%EB%B3%80%EB%9F%89-%EA%B0%80%EC%9A%B0%EC%8B%9C%EC%95%88-%EB%B6%84%ED%8F%ACMultivariate-Gaussian-Distribution">https://dhpark1212.tistory.com/entry/다변량-가우시안-분포Multivariate-Gaussian-Distribution</a></li>
        </ul>
      </li>
      <li>transformed Gaussian</li>
      <li>whitening transformation
        <ul>
          <li>it transforms a random variable vector with covariance into a new variable vector whose covariance is the identity matrix</li>
        </ul>
      </li>
      <li>transformed densities</li>
      <li>limitations of Gaussian distribution
        <ul>
          <li>there are too many parameters in general</li>
          <li>it is intrinsically unimodal</li>
        </ul>
      </li>
      <li>stationary process</li>
      <li>basic distributions: uniform</li>
      <li>basic distributions: Bernoulli
        <ul>
          <li>Discrete probability distribution</li>
        </ul>
      </li>
      <li>basic distributions: binomial
        <ul>
          <li>the probability of observing occurrences of in a set of samples from a Bernoulli distribution</li>
        </ul>
      </li>
      <li>basic distributions: categorical and multinomial</li>
    </ul>
  </li>
</ul>]]></content><author><name>JSC</name><email>newwin0198@handong.ac.kr</email></author><category term="ML" /><category term="ML" /><summary type="html"><![CDATA[Prob and Stats are the fundamentals. by Prof. Henry Choi]]></summary></entry><entry><title type="html">2023-HGU-ML Lecture 1. Introduction to AI and ML</title><link href="http://localhost:4000/recent/Introduction_to_AI_ML/" rel="alternate" type="text/html" title="2023-HGU-ML Lecture 1. Introduction to AI and ML" /><published>2023-12-17T00:00:00+09:00</published><updated>2023-12-17T00:00:00+09:00</updated><id>http://localhost:4000/recent/Introduction_to_AI_ML</id><content type="html" xml:base="http://localhost:4000/recent/Introduction_to_AI_ML/"><![CDATA[<h1 id="introduction-to-ai--ml">Introduction to AI &amp; ML</h1>

<p>Came from Henry Choi’s Lecture and ChatGPT’s explanation</p>

<ul>
  <li>Introduction to AI
    <ul>
      <li>Weak and Strong AI
        <ul>
          <li>strong AI: understanding Chinese</li>
          <li>weak AI: simulating the ability to understand Chinese</li>
        </ul>
      </li>
      <li>Applied AI and General AI</li>
      <li>Computationalism and Connectionism
        <ul>
          <li>Computationalism
            <ul>
              <li>thoughts are computation on symbols
                <ul>
                  <li>Symbolic, interpretable</li>
                  <li>e.g) Turing Machine</li>
                </ul>
              </li>
            </ul>
          </li>
          <li>Connectionism
            <ul>
              <li>Information is represented in neurons and networks
                <ul>
                  <li>Low-level, black-box</li>
                  <li>Neural Networks</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Turing Test</li>
      <li>Implementation level and algorithmic level
        <ul>
          <li>Implmentation level: how the system is physically realized
            <ul>
              <li>AI and Human Intelligence are different</li>
            </ul>
          </li>
          <li>Algorithmic level: how the system does, what representation or process it uses
            <ul>
              <li>3 level for intelligent system
                <ul>
                  <li>Learning, Computational level(what the system does and why), Algorithmic level</li>
                </ul>
              </li>
              <li>Can achieve some intelligence on approximation</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Superintelligence
        <ul>
          <li>bootstrapping from “child machine”, brain emulation, biological cognition, brain-computer interface, networks, and organizations</li>
        </ul>
      </li>
      <li>Deep Neural Networks
        <ul>
          <li>Hebbian learning, perceptron, multilayer perceptron, deep neural networks</li>
        </ul>
      </li>
      <li>Practical AI risks
        <ul>
          <li>affected by viruses</li>
          <li>misused by people with bad intentions</li>
          <li>biased AI</li>
          <li>taking over roles</li>
          <li>unable to reject AI’s decision</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Introduction to ML
    <ul>
      <li>What is learning
        <ul>
          <li>a computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, <strong>if its performance at the tasks improves with the experiences</strong></li>
          <li>simple model (e.g., linear regression)</li>
          <li>for supervised learning
            <ul>
              <li>Learning</li>
              <li>Recognition</li>
            </ul>
          </li>
          <li>Complex models</li>
        </ul>
      </li>
      <li>Machine learning
        <ul>
          <li>Takes data and output  → Makes program</li>
          <li>source of knowledge is data</li>
        </ul>
      </li>
      <li>Workflow of machine learning
        <ul>
          <li>acquisition - data is gathered/collected from various sources</li>
          <li>preparation - data is cleaned, preprocessed, and eventually becomes a dataset</li>
          <li>analysis - data is evaluated to run and customize reports</li>
          <li>modeling - data is patternized and generalized as models</li>
          <li>visualization</li>
          <li>deployment and maintenance</li>
        </ul>
      </li>
      <li>Components of ML
        <ul>
          <li>data: features, label, format</li>
          <li>models: SVM, NN, K-means</li>
          <li>objectives: cross-entropy, RMSE, likelihood</li>
          <li>optimization - gradient descent, Newton, linear programming, convex optimization</li>
        </ul>
      </li>
      <li>Data
        <ul>
          <li>structured/unstructured</li>
        </ul>
      </li>
      <li>Categories
        <ul>
          <li>unsupervised learning
            <ul>
              <li>e.g., clustering, dimension reduction</li>
            </ul>
          </li>
          <li>supervised learning
            <ul>
              <li>e.g., speech/face recognition</li>
            </ul>
          </li>
          <li>semi-supervised learning
            <ul>
              <li>e.g., cancer detection</li>
            </ul>
          </li>
          <li>reinforcement learning
            <ul>
              <li>e.g., AlphaGo, self-driving car</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Discriminative model and Generative model
        <ul>
          <li>
            <table>
              <tbody>
                <tr>
                  <td>Discriminative models: p(t</td>
                  <td>x)</td>
                </tr>
              </tbody>
            </table>
            <ul>
              <li>only for supervising</li>
            </ul>
          </li>
          <li>
            <table>
              <tbody>
                <tr>
                  <td>Generative model: p(t, x) or p(x</td>
                  <td>t)</td>
                </tr>
              </tbody>
            </table>
            <ul>
              <li>applicable to unlabeled data</li>
              <li>focusing on modeling each class’ distribution</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Pattern Recognition
        <ul>
          <li>measuring → preprocessing → dimensionality reduction → prediction → model selection
  -</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>]]></content><author><name>JSC</name><email>newwin0198@handong.ac.kr</email></author><category term="ML" /><category term="ML" /><summary type="html"><![CDATA[AI and ML Intro. by Prof. Henry Choi]]></summary></entry><entry><title type="html">And Then There Were None 그리고 아무도 없었다</title><link href="http://localhost:4000/recent/And_Then_There_Were_None/" rel="alternate" type="text/html" title="And Then There Were None 그리고 아무도 없었다" /><published>2023-07-16T00:00:00+09:00</published><updated>2023-07-16T00:00:00+09:00</updated><id>http://localhost:4000/recent/And_Then_There_Were_None</id><content type="html" xml:base="http://localhost:4000/recent/And_Then_There_Were_None/"><![CDATA[<p>추리 소설을 추천받았다. 아가사 크리스티의 <strong><em>그리고 아무도 없었다</em></strong> 였다. <br /> 
소설을 그렇게 좋아하는 편은 아니라 이름만 들어본 작가였지만 오랜만에 소설을 읽어보자는 마음으로 책을 집어들었다.</p>

<p>와우. 정말 재밌게 읽었다. 그 자리에 앉아서 내리 2시간을 읽었다. <del>물론 소설이 짧기도 하다</del> <br />
알고 보니 내 주위는 다들 읽었더라… 이 재밌는 걸 자신들만 알고 있었다니…</p>

<p>물론 선입견빼면 시체인 내가 추리 소설을 추천 받았더라도 내가 내키지 않았으면 안 읽었을 것 같긴 하다.
뭐든지 한 번 정도 시도해보고 판단하는게 맞는 것 같다는 생각이 근래에 많이 든다.</p>

<p>그 정도로 책이 재밌었다. 다음엔 <strong><em>오리엔트 특급 살인</em></strong> 읽어볼까 싶다!</p>]]></content><author><name>JSC</name><email>newwin0198@handong.ac.kr</email></author><category term="Books" /><category term="Blog" /><summary type="html"><![CDATA[재밌다...]]></summary></entry><entry><title type="html">Clean Code Chapter 3</title><link href="http://localhost:4000/recent/Clean_Code_Ch3/" rel="alternate" type="text/html" title="Clean Code Chapter 3" /><published>2023-07-16T00:00:00+09:00</published><updated>2023-07-16T00:00:00+09:00</updated><id>http://localhost:4000/recent/Clean_Code_Ch3</id><content type="html" xml:base="http://localhost:4000/recent/Clean_Code_Ch3/"><![CDATA[<p>How can we make a function communicate its intent?</p>

<p>What attributes can we give that will allow a reader to intuit the kind of program they live inside?</p>

<p><strong><em>The function should be very small</em></strong></p>

<ul>
  <li>In 1999, every function was just two, three, or four lines long
    <ul>
      <li>Each was transparent and led to the next in a compelling order</li>
    </ul>
  </li>
  <li>Block and Indenting
    <ul>
      <li>block within if, else, while and so on should be one line long
        <ul>
          <li>The line must be a function call</li>
          <li>The function should not be large enough to hold the nested structure</li>
          <li>The indent level of a function should not be greater than one or two</li>
        </ul>
      </li>
    </ul>

    <p><strong><em>Function Should Do One Thing</em></strong></p>
  </li>
  <li>What is one thing?
    <ul>
      <li>If a function does only that is on one level below the stated name of the function, then the function is doing one thing</li>
      <li>Decomposing a larger concept</li>
      <li>Simply restates the code without changing the level of abstraction</li>
      <li>if you can extract another function from it with a name that is not merely a restatement of its implementation</li>
      <li>A function that does one thing cannot be divided</li>
    </ul>
  </li>
  <li>One level of abstraction per function
    <ul>
      <li>Statements within the function are all at the same level of abstraction</li>
    </ul>
  </li>
  <li>Reading code from Top to Bottom: The Stepdown Rule
    <ul>
      <li>Top-down Narrative</li>
      <li>Reading program, descending one level of abstraction at a time as we read down the list of function</li>
      <li>Each function introduces the nest, and each function remains at a consistent level of abstraction</li>
    </ul>
  </li>
  <li>Avoid using switch statements
    <ul>
      <li>Each statement is buried in a low-level class and is never repeated</li>
      <li>Switch Statements can be tolerated if they appear only once</li>
      <li>Used to create polymorphic objects; hidden behind an inheritance relationship</li>
    </ul>
  </li>
  <li>Simple Responsibility Principle
    <ul>
      <li><a href="https://en.wikipedia.org/wiki/Single-responsibility_principle">https://en.wikipedia.org/wiki/Single-responsibility_principle</a></li>
    </ul>
  </li>
  <li>Open Closed Principle
    <ul>
      <li><a href="https://en.wikipedia.org/wiki/Open%E2%80%93closed_principle">https://en.wikipedia.org/wiki/Open–closed_principle</a></li>
    </ul>
  </li>
  <li>Use Descriptive Names
    <ul>
      <li>Choose descriptive names to clarify the design of the module in mind</li>
      <li>Don’t be afraid to make a name long</li>
      <li>Be consistent in names</li>
    </ul>
  </li>
</ul>

<p><strong><em>The argument is at a different level of abstraction</em></strong></p>

<ul>
  <li>Function Arguments
    <ul>
      <li>The ideal number argument for a function is zero(niladic)</li>
      <li>An argument forces the user to know the details</li>
    </ul>
  </li>
  <li>Arguments are hard at the testing point of a view
    <ul>
      <li>Need to test all combinations of arguments</li>
      <li>Output arguments are harder to understand than input arguments</li>
      <li>Don’t expect information to be going out through arguments</li>
    </ul>
  </li>
  <li>Common Monadic(one argument) function
    <ul>
      <li>Usage of arguments
        <ul>
          <li>Asking questions about arguments</li>
          <li>Operating on arguments, transforming the arguments</li>
        </ul>
      </li>
      <li><em>Event: there are input arguments but no output arguments</em>
        <ul>
          <li>The intention of calling the event is to use the argument the alter the state of the system</li>
          <li>Usage should be very clear that reader must notice this function is the event</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Flag Arguments
    <ul>
      <li><em>It is Ugly</em></li>
      <li>Split function instead of flag</li>
    </ul>
  </li>
</ul>

<p>Dyadic Functions</p>

<ul>
  <li>Should be avoided, but there is a situation in that dyadic function is necessary</li>
  <li>Take advantage of what mechanisms may be available to convert them into single-argument functions</li>
</ul>

<p>Triads Functions</p>

<ul>
  <li>Very careful to use it</li>
</ul>

<p>Argument Objects</p>

<ul>
  <li>When a group of variables is passed together, it is likely part of a concept that deserves a name of its own</li>
  <li>Augment list
    <ul>
      <li>Functions that take variable arguments can be monads, dyads, or even triads, but no more than that</li>
    </ul>
  </li>
</ul>

<p>Verb and Keywords</p>

<ul>
  <li>Monad case
    <ul>
      <li>the function and argument should form a very nice verb/noun pair</li>
    </ul>
  </li>
  <li>Using keywords to form a function name</li>
  <li>Function name and ordering of argument</li>
  <li>No side Effect
    <ul>
      <li>No temporal coupling</li>
      <li>State exactly what the function does and split the function if it is possible</li>
    </ul>
  </li>
  <li>Output arguments
    <ul>
      <li>Anything that forces you to check the function signature is equivalent to a double-take</li>
      <li><em>this</em> keyword is intended to act as an output argument</li>
      <li>Output argument should be avoided</li>
    </ul>
  </li>
</ul>

<p><strong><em>Do something or answer something, but not both</em></strong></p>

<p>Command Query Separation</p>

<ul>
  <li>Separate the command from the query so that ambiguity cannot occur</li>
</ul>

<p>Prefer Exception to Return Error Codes</p>

<ul>
  <li>Processing code can be separated from the happy path code and can be simplified</li>
  <li>Extract Try/Catch Block
    <ul>
      <li>Specific function for error handling</li>
      <li>It makes help to clarify the function
        <ul>
          <li>Nice Separation</li>
        </ul>
      </li>
      <li>Error Handling is one thing; function should only be one thing</li>
    </ul>
  </li>
  <li>New exceptions are derivatives of the exception class</li>
</ul>

<p>Don’t Repeat Yourself</p>

<ul>
  <li>Duplication may be the root of all evil in software</li>
  <li>Since the invention of the subroutine, innovations have been an ongoing attempt to eliminate duplication from our source code</li>
</ul>

<p>Structured Programming</p>

<ul>
  <li>Only be one <em>return</em> statement</li>
  <li>No <em>break</em> or <em>continue</em> statement</li>
  <li>Never <em>goto</em> statement</li>
  <li>These rules are beneficial for large functions, not small functions</li>
</ul>

<p>How to write a function with these rules?</p>

<ul>
  <li>Write code</li>
  <li>Message and refine the code, shrink and reorder, and keeping the test passing</li>
</ul>

<p>Conclusion</p>

<ul>
  <li>Functions are the verb</li>
  <li>Classes are the nouns</li>
  <li>The art of programming is the art of language design</li>
  <li>A function will be short, well-named, nicely organized</li>
  <li><strong><em>Tell the story of the system</em></strong>
    <ul>
      <li>need to fit cleanly together in precise language</li>
    </ul>
  </li>
</ul>]]></content><author><name>JSC</name><email>newwin0198@handong.ac.kr</email></author><category term="Books" /><category term="Blog" /><summary type="html"><![CDATA[Using Function Properly]]></summary></entry><entry><title type="html">Can We Automatically Fix Bugs by Learning Edit Operations?</title><link href="http://localhost:4000/recent/Can-We-Automatically-Fix-Bugs-by-Learning-Edit-Operations/" rel="alternate" type="text/html" title="Can We Automatically Fix Bugs by Learning Edit Operations?" /><published>2023-07-13T00:00:00+09:00</published><updated>2023-07-13T00:00:00+09:00</updated><id>http://localhost:4000/recent/Can%20We%20Automatically%20Fix%20Bugs%20by%20Learning%20Edit%20Operations</id><content type="html" xml:base="http://localhost:4000/recent/Can-We-Automatically-Fix-Bugs-by-Learning-Edit-Operations/"><![CDATA[<h2 id="can-we-automatically-fix-bugs-by-learning-edit-operations">“Can We Automatically Fix Bugs by Learning Edit Operations?”</h2>

<h2 id="paper"><a href="https://www.cs.wm.edu/~denys/pubs/SANER-RENE-BugFixing.pdf">Paper</a></h2>

<h3 id="summary">Summary:</h3>

<ul>
  <li>
    <p>Implementing Hephaestus, a novel method to improve the accuracy of APR through learning to apply edit operations. Leverages neural machine translation and attempts to produce the edit operations needed.</p>

    <p>Learning edit operations does not offer an advantage over the standard approach of translating directly from buggy code to fixed code. However, interestingly, Hephaestus exhibited lower translation accuracy than the baseline, able to perform successful bug repair.</p>
  </li>
</ul>

<h3 id="points">Points:</h3>

<ol>
  <li>Introduction
    <ol>
      <li>The naive approach attempts some sort of comparison algorithm that identifies the type of bug and replaces it with a prescribed bugs
        <ol>
          <li>Time Consuming</li>
        </ol>
      </li>
      <li>Learning approach using neural machine translation</li>
      <li>Directly applying the NMT approach to source code is inefficient
        <ol>
          <li>Many bugs fixes involve changes to a few sentences
            <ol>
              <li>Results in suboptimal performances</li>
            </ol>
          </li>
          <li>Attempt to mitigate the inefficiency by predicting the specific statement on AST</li>
          <li>Attempting on individual tokens would be more optimal</li>
        </ol>
      </li>
      <li>Hephaestus leverages NMT to predict edit operation, derived from Levenshtein Distance Algorithm
        <ol>
          <li>Working at the token level of source code</li>
          <li>Work on any language without language-specific parsers</li>
        </ol>
      </li>
    </ol>
  </li>
  <li>Related Works
    <ol>
      <li>Tufano et al.
        <ol>
          <li>Repairing code through identification of bug-fix patterns in large software repositories</li>
          <li>Usage of Deep Learning Approach regarding “meaningful” change</li>
        </ol>
      </li>
      <li>Chen et al.
        <ol>
          <li>Focus on single-line bug</li>
        </ol>
      </li>
      <li>Jiang et al.
        <ol>
          <li>The correct fix for a given bug does not exist within the model’s output space and the model’s lack of awareness of syntax</li>
          <li>Pre-train model on the programming language in question</li>
        </ol>
      </li>
      <li>Yuan and Banzhaf
        <ol>
          <li>grouping fine-granularity edits into larger statement-level edits</li>
        </ol>
      </li>
      <li>Mousavi et al.
        <ol>
          <li>Overfitting and Disparity between predicted bug and fix operation and would mimic a human software developer</li>
        </ol>
      </li>
    </ol>
  </li>
  <li>Background
    <ol>
      <li>Fixing buggy code to fixed code using traditional language translation matter of the buggy to fix a variety of language</li>
      <li>Traditional translation replaces the majority of the input sequence which is natural language.
        <ol>
          <li>Fix in code might be minimal</li>
          <li>repair translation should not have the same meaning as the input</li>
        </ol>
      </li>
    </ol>
  </li>
  <li>Approach
    <ol>
      <li>Levenshtein Edit Operation
        <ol>
          <li>the bug is input sequence, the NMT model attempts to produce edit operations</li>
          <li>Basic Operations
            <ol>
              <li>Insertion</li>
              <li>Deletion</li>
              <li>Replacement</li>
            </ol>
          </li>
        </ol>
      </li>
      <li>Compound Edit Operations
        <ol>
          <li>Group of one or more edit operations; sequence of operations</li>
          <li>Condensing: A grouping process to compound operations</li>
        </ol>
      </li>
      <li>Dataset Construction
        <ol>
          <li>Control Dataset: baseline, not involved with edit operations</li>
          <li>Machine String: In order to include edit operations, transforming edit operations
            <ol>
              <li>Typed</li>
              <li>General</li>
            </ol>
          </li>
          <li>We make the distinction between typed and general form to determine if the form of machine string used during training affects the Hephaestus models’ abilities to learn edit operations.</li>
        </ol>
      </li>
      <li>Experimental Dataset
        <ol>
          <li>translate the bug into its corresponding fix, showing Levenshetein edit distance between the bug and fix</li>
          <li>all basic compound operation sequences which transform the bug into the fix, strict is the minimal sequence of the strict compound operation sequences, and loose is the minimal sequence of the loose compound operation sequences</li>
        </ol>
      </li>
      <li>Model Construction
        <ol>
          <li>LSTM+General</li>
          <li>GRU+General</li>
          <li>LSTM+Typed</li>
        </ol>
      </li>
      <li>The CEC ensures that error signals fed forward into the LSTM layers and backpropagated to the LSTM layers are resistant to the effects of the vanishing gradient problem.</li>
    </ol>
  </li>
  <li>Experimental Design
    <ol>
      <li>Perfect Prediction Accuracy</li>
      <li>Failed Prediction Rate</li>
      <li>Edit Distance Decrease</li>
      <li>Training Accuracy</li>
    </ol>
  </li>
  <li>Result
    <ol>
      <li>PPA: The control model (baseline model) outperformed the rest, with no much difference</li>
      <li>FPR: The control model maintained 100% capability, the string can always be interpreted as a sequence of Java method tokens</li>
      <li>EDD: every model generates “bug fixes” that were further away from the fixed code than the original buggy code</li>
      <li>Training Accuracy: Every model exceeded 90%</li>
    </ol>
  </li>
  <li>RQ
    <ol>
      <li>RQ1: Is learning edit operations an effective approach to automatic bug repair?
        <ol>
          <li>learning edit operations does not offer advantages over the baseline approach. The experimental Hephaestus models must determine a sequence of edit operations, decode them, and apply them to the inputted buggy method in order to predict fixed source code</li>
        </ol>
      </li>
      <li>RQ2: What effect does each condensing strategy and machine string form have on the accuracy of bug repair?
        <ol>
          <li>The differences in PPA between the basic, strict, and loose models are negligible, but there are differences according to the training accuracy and average EDD values. Despite having significantly lower final training accuracy, the strict and loose models had slightly more positive EDD values than the basic models (a difference of about 0.96). Thus, it is evidenced that condensing edit operations into strict and loose forms are beneficial over not condensing them at all</li>
        </ol>
      </li>
      <li>RQ3: What is the effect of using an LSTM-based architecture versus a GRU-based architecture on the accuracy of bug repair?
        <ol>
          <li>the variation is not meaningful enough to consider as a key difference between the models.</li>
        </ol>
      </li>
      <li>Future Work
        <ol>
          <li>It was determined that most failed predictions were caused by generated indices outside the valid range for a given string. What changes can be made to this model to restrict the prediction range?</li>
          <li>does changing the abstraction method of the training dataset affect this metric?</li>
          <li>Other NLP Tools</li>
          <li>Extra software layers in addition to the methods presented in our study.</li>
        </ol>
      </li>
      <li>Conclusion
        <ol>
          <li>The introduction of these specific methods for training NMTbased systems to learn bug fixes did not provide a benefit to the task</li>
          <li>Edit operations are capable of performing automated bug repair to some degree</li>
        </ol>
      </li>
    </ol>
  </li>
</ol>

<h3 id="knowledge">Knowledge:</h3>

<ul>
  <li>NMT (Neural Machine Translation): <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">Neural machine translation - Wikipedia</a>uses an artificial neural work to predict the likelihood of a sequence of words</li>
  <li>Levenshtein Distance Algorithm: A string metric for measuring the difference between two sequences. This is likely due to the experimental models experiencing higher entropy than the control when making predictions.</li>
</ul>

<h3 id="terminology">Terminology:</h3>

<ul>
  <li>Condensing Strategies:
    <ul>
      <li>Basic Condensing: basic compound operation corresponds with exactly one change</li>
      <li>Loose Condensing: iff the application of its constituent operation is equivalent to the application of some singular op
        <ul>
          <li>Modify a contiguous section of tokens</li>
        </ul>
      </li>
      <li>Strict Condensing: iff it is loosely compatible and every operation is of the same flavor</li>
    </ul>
  </li>
  <li>Machine Strings:
    <ul>
      <li>Typed: f is one of ins, del, or rep, depending on if the flavor of the represented edit operation is insertion, deletion, or replacement, respectively</li>
      <li>General: general form machine strings do not explicitly store the flavor of their represented edit operations</li>
    </ul>
  </li>
</ul>

<h3 id="tool">Tool:</h3>

<p><a href="https://github.com/WM-SEMERU/hephaestus">GitHub - WM-SEMERU/hephaestus</a></p>

<h3 id="questions">Questions:</h3>]]></content><author><name>JSC</name><email>newwin0198@handong.ac.kr</email></author><category term="APR" /><category term="APR" /><summary type="html"><![CDATA[Generalizing the change is helpful...?]]></summary></entry><entry><title type="html">Clean Code Chapter 2</title><link href="http://localhost:4000/recent/Clean_Code_Ch2/" rel="alternate" type="text/html" title="Clean Code Chapter 2" /><published>2023-07-13T00:00:00+09:00</published><updated>2023-07-13T00:00:00+09:00</updated><id>http://localhost:4000/recent/Clean_Code_Ch2</id><content type="html" xml:base="http://localhost:4000/recent/Clean_Code_Ch2/"><![CDATA[<p><strong>Using the appropriate Name will pay off in the short term and continue to pay in the long run</strong></p>

<ul>
  <li>Using Intention-Revealing Names
    <ul>
      <li>Choosing good names takes time but saves more than it takes</li>
      <li>Choosing a name that specifies what is being measured and the unit of that measurement</li>
      <li>Things need to think
        <ul>
          <li>What kind are in</li>
          <li>What is returned</li>
          <li>zeroth subscript and value</li>
        </ul>
      </li>
      <li>Do not use <strong>O <em>and l</em></strong></li>
    </ul>
  </li>
  <li>Avoid Disinformation
    <ul>
      <li>Avoiding words whose entrenched meanings vary from intention</li>
      <li>Spelling similar concepts similarly
        <ul>
          <li>No inconsistent spelling</li>
        </ul>
      </li>
      <li><del>Using different font??</del></li>
    </ul>
  </li>
  <li>Meaningful Distinction
    <ul>
      <li><strong>a</strong> for a local variable, <strong>the</strong> for all function arguments</li>
      <li>Less redundant words</li>
      <li>Distinguishing names in a way that readers know what the difference offer</li>
    </ul>
  </li>
  <li>Using Pronounceable Names
    <ul>
      <li>Essential for communication</li>
    </ul>
  </li>
  <li>Using Searchable Names
    <ul>
      <li>Single-letter names can ONLY be used as local variables inside short methods</li>
      <li>The length of a name should correspond to the size of its scope</li>
    </ul>
  </li>
  <li>Avoiding Encoding</li>
  <li>Hungarian Notation
    <ul>
      <li>The compiler knows the type nowadays</li>
    </ul>
  </li>
  <li>Member Prefixes
    <ul>
      <li>unseen clutter and a marker of older code…</li>
    </ul>
  </li>
  <li>Interface and Implementation
    <ul>
      <li>Why would I let user knows I’m handling them with an interface?</li>
      <li>Marking at the implementation</li>
    </ul>
  </li>
  <li>Avoid Mental Mapping
    <ul>
      <li>In most contexts, a single letter for a loop is a poor choice (such as i, j, k)</li>
      <li><em>Clarity is king</em></li>
    </ul>
  </li>
  <li>Class Names
    <ul>
      <li>should have noun or noun phrase names</li>
    </ul>
  </li>
  <li>Method Names
    <ul>
      <li>should have verb or verb phase names</li>
      <li>When constructors are overloaded, use the static method with names that describe the argument
        <ul>
          <li>Make corresponding constructors private</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Don’t be cute
    <ul>
      <li>No too “user-specific name”</li>
    </ul>
  </li>
  <li>Pick One Word per Concept
    <ul>
      <li>Pick one word for one abstract concept</li>
      <li>The name will express two different types of object</li>
    </ul>
  </li>
  <li>Don’t Pun
    <ul>
      <li>Avoiding using the same word for two purposes</li>
      <li>Even if it has a similar concept, it must have a different name if it is semantically different</li>
      <li><strong><em>It is the author’s responsibility</em></strong></li>
    </ul>
  </li>
  <li>Use Solution Domain Names
    <ul>
      <li>People who read your code will be programmers
        <ul>
          <li>CS terms, algorithm names, pattern names, math terms, etc.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Use Problem Domain Names
    <ul>
      <li>Separating solution and problem domain concept</li>
    </ul>
  </li>
  <li>Add Meaningful Context
    <ul>
      <li>Place the name in context for the reader
        <ul>
          <li>enclosing classes, functions, or namespaces</li>
        </ul>
      </li>
      <li>break it into smaller functions if it is necessary</li>
    </ul>
  </li>
  <li>But Don’t Add Gratuitous Context
    <ul>
      <li>Shorter names are generally better
        <ul>
          <li>As long as they are clear</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>]]></content><author><name>JSC</name><email>newwin0198@handong.ac.kr</email></author><category term="Books" /><category term="Blog" /><summary type="html"><![CDATA[How to name clearly]]></summary></entry></feed>