<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-07-09T20:01:36+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">JSC‚Äôs DevLog</title><subtitle>SE and AI version 1.0</subtitle><author><name>JSC</name><email>newwin0198@handong.ac.kr</email></author><entry><title type="html">Operating Systems: Three Easy Pieces Ch. 20</title><link href="http://localhost:4000/recent/Chapter-20/" rel="alternate" type="text/html" title="Operating Systems: Three Easy Pieces Ch. 20" /><published>2023-05-12T00:00:00+09:00</published><updated>2023-05-12T00:00:00+09:00</updated><id>http://localhost:4000/recent/Chapter-20</id><content type="html" xml:base="http://localhost:4000/recent/Chapter-20/"><![CDATA[<p>Paging: Smaller Tables</p>

<p>Page tables are too big and thus consume too much memory.</p>

<ul>
  <li>32-bit address space (2^32 bytes), with 4KB (2^12 bytes) and 4-byte page-table entry
    <ul>
      <li>Simple array-based page tables are too big, taking up far too much memory on typical systems</li>
      <li>We are in search of some techniques to reduce</li>
    </ul>
  </li>
  <li>Simple solution: Bigger pages
    <ul>
      <li>Increasing the page size may decrease the page table size</li>
      <li>But internal fragmentation will occur</li>
    </ul>
  </li>
  <li>Hybrid approach: Paging and Segments
    <ul>
      <li>Instead of having a single-page table for the entire address space of the process, why not have one per logical segment?</li>
      <li>We still have MMU ‚Üí hold the physical address of the page table of that segment</li>
      <li>Three base/bound pairs, one each for code, heap, and tack
        <ul>
          <li>When the process is running, the base register for each of these segments contains the physical address of a linear page table for that segment</li>
          <li>each process in the system now has a three-page table associated with it</li>
          <li>On a context switch, these registers must be changed to reflect the location of the page tables of the newly-running process</li>
        </ul>
      </li>
      <li>On the TLB miss ‚Üí hardware uses the segment bits to determine which base and bound pair to use
        <ul>
          <li>Hardware takes the physical address and combines it with VPN to form an address of the page table entry</li>
          <li>The critical difference in our hybrid scheme is the presence of a bounds register per segment</li>
          <li>But‚Ä¶
            <ul>
              <li>if we have a sparsely-used heap, we can still end up with a lot of page table waste</li>
              <li>since most of the memory is managed in <strong>page-sized units</strong>, page tables can be of arbitrary size, and finding free space is complicated</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Multi-level page tables
        <ul>
          <li>chop up the page table into page-sized units, then if an entire page of page-table entries is invalid, don‚Äôt allocate that page of the page table at all</li>
          <li>Page directory</li>
          <li>The page directory, in a simple two-level table, contains one entry per page of the page table</li>
          <li>consists of a number of page directory entries (PDE)</li>
          <li>A PDE (minimally) has a valid bit and a page frame number (PFN), similar to a PTE.
            <ul>
              <li>But the meaning of valid bit is different, if it is valid, it means at least one of the pages of the page table that the entry points to is valid</li>
            </ul>
          </li>
          <li>the multi-level table only allocates page-table space in proportion to the amount of address space you are using</li>
          <li>each portion of the page table fits neatly within a page, making it easier to manage memory</li>
          <li>level of indirection using the page directory, which points to pieces of the page tables</li>
          <li>In the case of miss
            <ul>
              <li>two loads from memory will be required
                <ul>
                  <li>one for the page directory, one for PTE itself</li>
                </ul>
              </li>
              <li>time-space tradeoff</li>
              <li>complexity</li>
            </ul>
          </li>
          <li>To build a two-level page table for this address space, we start with our full linear page table and break it up into page-sized units.</li>
          <li>As a result, we need four bits of the VPN to index into the directory; we use the top four bits of the VPN</li>
          <li>page-directory entry (PDE) with a simple calculation: PDEAddr = PageDirBase + (PDIndex * sizeof(PDE)).</li>
        </ul>
      </li>
      <li>More than two-levels</li>
      <li>Translation process
        <ul>
          <li>the physical address is formed directly without accessing the page table at all, as before. Only upon a TLB miss does the hardware need to perform the full multi-level lookup.</li>
        </ul>
      </li>
      <li>Inverted Page Tables
        <ul>
          <li>Even more extreme space saving in the world of page tables is found with inverted page tables</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>some systems place such page tables in kernel virtual memory, allowing the system to swap some page tables to disk when memory pressure gets a little tight.</li>
</ul>

<p>In summary, it also introduces increased complexity, potential memory overhead, challenges in address translation and memory protection, and fragmentation concerns, which need to be carefully considered and managed in the design and implementation of such a memory management scheme.</p>

<p>PTE ‚Üí bitÏùò ÏàúÏÑúÏôÄ optimization</p>]]></content><author><name>JSC</name><email>newwin0198@handong.ac.kr</email></author><category term="OS" /><category term="OS" /><summary type="html"><![CDATA[OS Ch.20]]></summary></entry><entry><title type="html">OS-HW2 Summary</title><link href="http://localhost:4000/recent/OS-HW2/" rel="alternate" type="text/html" title="OS-HW2 Summary" /><published>2023-05-12T00:00:00+09:00</published><updated>2023-05-12T00:00:00+09:00</updated><id>http://localhost:4000/recent/OS-HW2</id><content type="html" xml:base="http://localhost:4000/recent/OS-HW2/"><![CDATA[<h1 id="hw-2">HW 2</h1>

<p>First of all, it was the first assignment that I have not completed since I start Computer Science Major‚Ä¶ I slept 11 hours for 4 days.</p>

<ul>
  <li>Delta debugging:
    <ul>
      <li>a test input minimization technique that takes a target program together with a crashing test input, and then automatically derives a part of the test input that still makes the program crash.</li>
      <li>This algorithm receives three inputs: (1) ùëù, an executable binary of a target program, (2) ùë°, a test input that crashes the target program, and (3) ùëê, a condition to determine the crash.</li>
    </ul>
  </li>
  <li>
    <p>Overall requirement</p>

    <p>it checks if the regions of size ùë† (Line 13) crash ùëù while preserving the crash behavior. If found, the algorithm updates ùë°ùëö and continues the reduction with it (Lines 14-17). If the algorithm could not find a reduced crashing input with ùë†, it decrements s by one (Line 19), and repeats the input subsequence exploration until ùë† becomes zero (Line 3)</p>

    <ul>
      <li>User interface:
        <ul>
          <li>must return an error message if a given argument is invalid</li>
          <li>option arguments
            <ul>
              <li>I option: receive full path of the crashing input</li>
              <li>m option: string appeared in the standard error</li>
              <li>o option: new file to store the reduced crashing input</li>
            </ul>
          </li>
          <li>After the option arguments
            <ul>
              <li>executable binary of the target program</li>
              <li>If the target program needs to receive its own command-line arguments, multiple arguments must be given.</li>
            </ul>
          </li>
          <li>User interrupt
            <ul>
              <li>Ctrl+C: for this case, cimin must stop the running test if exists, and prints out the size of the shortest crashing input found so far, produces the output with it, and terminates the execution.</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>System Design
        <ul>
          <li>Running the target program
            <ul>
              <li>To run the target program, cimin must use fork() to create a new process, and exec() (or its variants) to load the target program in the created process.</li>
              <li>Assumption: receives input via standard input and sends out crash message to standard error</li>
            </ul>
          </li>
          <li>Using Pipe
            <ul>
              <li>Target program receives input via standard input and sends out crash message to standard error. To pass input to the target program, cimin must use unnamed pipe (i.e., pipe()) to redirect standard input.</li>
              <li>Also, it use to redirect the standard error to receive the error message from the target program execution</li>
              <li>Assumption: We assume that the target program produces crash message to standard error, and we can find a keyword to determine if the same crash happens with reduced inputs.</li>
            </ul>
          </li>
          <li>Using signal
            <ul>
              <li>cimin must reject the initial crashing input if its execution takes more than 3 seconds.</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Buggy Programs
        <ul>
          <li>jsmn
            <ul>
              <li>Bug with heap-buffer overflow errors</li>
              <li>LLVM AddressSanitizer ‚Üí explicitly detect an occurrence of heap-buffer overflow buffer</li>
              <li>You can characterize this crashing message by checking if it has ‚ÄúAddressSanitizer: heap-buffer-overflow‚Äù.</li>
            </ul>
          </li>
          <li>libxml2
            <ul>
              <li>Bugs with null pointer deference errors.</li>
              <li>You can trigger this bug by executing xmllint with option ‚Äú‚Äìrecover ‚Äìpostvalid -‚Äù and passing libxml2/testcases/crash.xml to standard input.</li>
              <li>The crashing symptom can be identified by checking if ‚ÄúSEGV on unknown address‚Äù is printed to standard error. This error message is produced by LLVM AddressSanitizer when a crash occurs by null pointer dereference.</li>
            </ul>
          </li>
          <li>balance
            <ul>
              <li>balance is a toy example program that checks if the given input has well-balanced parenthesis or not.</li>
              <li>When this program receives balance/testcases/fail via standard input, it will fall into infinite loop.</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Report writing
        <ul>
          <li>Must not exceed 3 pages</li>
          <li>Note that the evaluation is primary based on your report, and your implementation will be tested to check whether it consistently works as described in the report</li>
        </ul>
      </li>
      <li>Submission
        <ul>
          <li>Report ‚Üí PDF</li>
          <li>Makefile</li>
          <li><a href="http://README.md">README.md</a></li>
          <li>Runnable at the peace.handong.edu</li>
        </ul>
      </li>
    </ul>

    <p>Crash_copy.json</p>

    <p>‚Üí Only with the new line character ‚Üí no output</p>
  </li>
</ul>]]></content><author><name>JSC</name><email>newwin0198@handong.ac.kr</email></author><category term="OS" /><category term="OS" /><summary type="html"><![CDATA[OS HW 2... Prof. Hong...]]></summary></entry><entry><title type="html">Operating Systems: Three Easy Pieces Ch. 16</title><link href="http://localhost:4000/recent/Chapter-16/" rel="alternate" type="text/html" title="Operating Systems: Three Easy Pieces Ch. 16" /><published>2023-04-20T00:00:00+09:00</published><updated>2023-04-20T00:00:00+09:00</updated><id>http://localhost:4000/recent/Chapter-16</id><content type="html" xml:base="http://localhost:4000/recent/Chapter-16/"><![CDATA[<p>Segmentation</p>

<ul>
  <li>Why not have a base and bounds pair per logical segment</li>
  <li>Segment independently in physical memory</li>
  <li>Sparse address spaces</li>
  <li>What we need to first do is extract the offset into the heap</li>
  <li>Illegal address ‚Üí segmentation fault</li>
  <li>Which Segment are we referring to?</li>
  <li>Explicit approach
    <ul>
      <li>upper two bits heap indicates which offset</li>
      <li>next 12 bits as the offset into the segment</li>
      <li>By adding the base register to the offset, the hardware arrives at the final physical space</li>
    </ul>
  </li>
  <li>Implicit approach
    <ul>
      <li>hardware determines the segment by noticing how the address was formed</li>
      <li>address is within the code segment</li>
    </ul>
  </li>
  <li>Stack
    <ul>
      <li>one critical difference, it grows backward</li>
      <li>hardware must now translate such virtual addresses slightly differently</li>
      <li>We simply add the negative offset to the base</li>
    </ul>
  </li>
  <li>Sharing
    <ul>
      <li>Code sharing</li>
      <li>Protection bit ‚Üí extra support from the hardware</li>
    </ul>
  </li>
  <li>Fine-grained vs Coarse-grained Segmentation
    <ul>
      <li>Coarse-grained
        <ul>
          <li>chops up the address space into relatively large</li>
        </ul>
      </li>
      <li>Fine-grained
        <ul>
          <li>allowed for address space to consist of a large number smaller segment</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Segment table
    <ul>
      <li>usually support the creation of a very large number</li>
    </ul>
  </li>
  <li>OS Support
    <ul>
      <li>OS must make sure to set up these registers correctly before letting the process run again.</li>
      <li>The second, and more important, issue is managing free space in physical memory.</li>
      <li>External fragmentation
        <ul>
          <li>The general problem that arises is that physical memory quickly becomes full of little holes of free space, making it difficult to allocate new segments, or to grow existing ones.</li>
          <li>One solution to this problem would be to compact physical memory by rearranging the existing segments.</li>
          <li>best fit</li>
          <li>worst fit</li>
          <li>first fit</li>
          <li>buddy algorithm</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Overall
    <ul>
      <li>Segmentation solves a number of problems, and helps us build a more effective virtualization of memory. Beyond just dynamic relocation, segmentation can better support sparse address spaces, by avoiding the huge potential waste of memory between logical segments of the address space.</li>
      <li>Problems
        <ul>
          <li>External fragmentation</li>
          <li>Segmentation is not flexible</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>]]></content><author><name>JSC</name><email>newwin0198@handong.ac.kr</email></author><category term="OS" /><category term="OS" /><summary type="html"><![CDATA[OS Ch.16]]></summary></entry><entry><title type="html">Operating Systems: Three Easy Pieces Ch. 19</title><link href="http://localhost:4000/recent/Chapter-19/" rel="alternate" type="text/html" title="Operating Systems: Three Easy Pieces Ch. 19" /><published>2023-04-20T00:00:00+09:00</published><updated>2023-04-20T00:00:00+09:00</updated><id>http://localhost:4000/recent/Chapter-19</id><content type="html" xml:base="http://localhost:4000/recent/Chapter-19/"><![CDATA[<p>Paging: Faster Translations</p>

<ul>
  <li>TLB: Translation-lookaside buffer
    <ul>
      <li>Part of MMU: Memory-management unit</li>
      <li>hardware cache: unlike memory cache, it is visible</li>
    </ul>
  </li>
  <li>Hardware-managed TLB
    <ol>
      <li>extract virtual page number from virtual address and check TLB holds a translation
        <ol>
          <li>TLB Hit : TLB hold the translation</li>
          <li>TLB Miss : TLB doesn‚Äôt have the translatinon
            <ol>
              <li>In the case, update the TLB with the translation</li>
              <li>It is costly since it has more memory access</li>
            </ol>
          </li>
        </ol>
      </li>
      <li>avoid TLB miss is important</li>
    </ol>
  </li>
  <li>Example
    <ul>
      <li>In the case of array
        <ul>
          <li>Since the array has continous memory, if we load memory unit by memory size, TLB hit occurs often</li>
        </ul>
      </li>
      <li>Spatial locality
        <ul>
          <li>The element of the array are packed tightly into pages</li>
        </ul>
      </li>
      <li>Temporal locality
        <ul>
          <li>Quick re-referencing of memory items in time</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Handling TLB miss
    <ul>
      <li>CISC (complex-instruction set computers), the old day system, engineer doesn‚Äôt believe OS
        <ul>
          <li>Therefore, hardware know exactly where the page tables located via a page-table base register</li>
          <li>Hardware-managed TLB, uses fixed multi-level page table</li>
        </ul>
      </li>
      <li>RISC (reduced-instrution set computers)
        <ul>
          <li>TLB miss occurs, hardware simply raise the exception</li>
          <li>Software-managed TLB</li>
          <li>On the TLB miss ‚Üí exception ‚Üí raises privileged level to kernel mode, and jumps to a trap handler</li>
          <li>Important details
            <ul>
              <li>return-from-trap instructions needs to be a little different
                <ul>
                  <li>It resume the execution from the instruction ‚Äúcause‚Äù the TLB miss because it now will occur TLB hit</li>
                </ul>
              </li>
              <li>TLB miss-handling, need to extra careful not to cause an infinite chain of TLB miss
                <ul>
                  <li>Many solutions ‚Üí keep TLB miss handler in physical memory</li>
                  <li>reserve some entries in the TLB for permanenetly-valid translations and use some of those permananent translation slots for the handler code it self ‚Üí wired translation</li>
                </ul>
              </li>
            </ul>
          </li>
          <li>Flexibility ‚Üí OS can use any data structure it wants to implement page table</li>
          <li>Simplicity ‚Üí the hardware doesn‚Äôt have to do much on a miss</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>TLB Content
    <ul>
      <li>TLB might have 32, 64, 128 entries with fully associative</li>
      <li>
        <table>
          <tbody>
            <tr>
              <td>VPN</td>
              <td>PFN</td>
              <td>other bits</td>
            </tr>
          </tbody>
        </table>
      </li>
      <li>Other bits
        <ul>
          <li>valid bit - whether the entry has a valid translation or not</li>
          <li>protection bit - how can a page can be accessed</li>
          <li>Address-space identifier</li>
          <li>dirty bit</li>
        </ul>
      </li>
      <li>Context switches
        <ul>
          <li>the TLB contains virtual-to-physical translations that are only valid for the currently running process; these translations are not meaningful for other processes.</li>
          <li>Need to be careful not to be use other TLB</li>
          <li>If there is same vpn, the hardware can‚Äôt distinguish which entry is meant for which process</li>
          <li>Solution
            <ul>
              <li>TLB flush
                <ul>
                  <li>flush the TLB on context switch, emptying TLB before running the new process
                    <ul>
                      <li>On a software-based system, this can be accomplished with an explicit (and privileged) hardware instruction; with a hardware-managed TLB, the flush could be enacted when the page-table base register is changed (note the OS must change the PTBR on a context switch anyhow)</li>
                      <li>There is a cost, it must incur TLB misses at it touches its data and code pages</li>
                    </ul>
                  </li>
                </ul>
              </li>
              <li>ASID
                <ul>
                  <li>address space identifier</li>
                  <li>TLB can hold same VPN with ASID without confusion</li>
                  <li>Two processes can share a page with this method</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Replacement policy
        <ul>
          <li>main issue: cache replacement; how can we replace?</li>
          <li>LRU(Least-recently-used)
            <ul>
              <li>take advantage of locality in the memory-reference stream</li>
            </ul>
          </li>
          <li>Random policy</li>
        </ul>
      </li>
      <li>The real TLB
        <ul>
          <li>Page 193</li>
        </ul>
      </li>
      <li>The use of TLBs in virtual memory systems can significantly improve address translation performance by caching frequently accessed page table entries on-chip, reducing the need to access main memory. This results in performance similar to that of non-virtualized memory. However, TLBs may be less effective for programs that access a large number of pages in a short time, leading to TLB misses and decreased performance. One solution to this issue is to use larger page sizes to increase TLB coverage, but TLB access can also become a bottleneck in the CPU pipeline, particularly with physically-indexed caches, and virtually-indexed caches introduce new hardware design issues.</li>
    </ul>
  </li>
</ul>]]></content><author><name>JSC</name><email>newwin0198@handong.ac.kr</email></author><category term="OS" /><category term="OS" /><summary type="html"><![CDATA[OS Ch.19]]></summary></entry><entry><title type="html">Operating Systems: Three Easy Pieces Ch. 18</title><link href="http://localhost:4000/recent/Chapter-18/" rel="alternate" type="text/html" title="Operating Systems: Three Easy Pieces Ch. 18" /><published>2023-04-20T00:00:00+09:00</published><updated>2023-04-20T00:00:00+09:00</updated><id>http://localhost:4000/recent/Chapter-18</id><content type="html" xml:base="http://localhost:4000/recent/Chapter-18/"><![CDATA[<p>Paging: Introduction</p>

<ul>
  <li>Page
    <ul>
      <li>Split up our address space into fixed-size units</li>
      <li>With paging, physical memory is also split into some number of pages as well ‚Üí page frame</li>
      <li>Advantages
        <ul>
          <li>Flexibility ‚Üí system will be able to support the abstraction of address space</li>
          <li>simplicity ‚Üí OS keeps a free list of all pages for this and just grabs the first four free pages off of the list</li>
        </ul>
      </li>
      <li>per-process data structure known as a page table
        <ul>
          <li>Main role: address translation</li>
        </ul>
      </li>
      <li>The inverted page table is not a per-process structure</li>
      <li>To translate the virtual address that the process generated
        <ul>
          <li>we have to split into VPN (Virtual page number) and offset</li>
          <li>movl 21, %eax ‚Üí convert 21 to 01<strong>0101,</strong> bold ‚Üí offset</li>
        </ul>
      </li>
      <li>Where are page tables stored?
        <ul>
          <li>for 4-KB pages ‚Üí 12-bit offset required</li>
          <li>20-bit VPN implies that there are 2^20 translations that OS would have to manage for each process</li>
          <li>Assume we need 4 bytes per page table entry to hold the physical translation plus other bits
            <ul>
              <li>If there is any process, the required bytes will be huge</li>
              <li>So, we store the page table for each process in memory</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Simple form ‚Üí Linear page table
        <ul>
          <li>for each content of each PTE, we have a number of different bits
            <ul>
              <li>valid bit: indicate whether the particular translation is valid
                <ul>
                  <li>unused ‚Üí invalid</li>
                </ul>
              </li>
              <li>protection bit: indicating whether the page could be read from</li>
              <li>present bit: indicate whether this page is in physical memory or on disk</li>
              <li>dirty bit: indicating whether the page has been modified since it was brought into memory</li>
              <li>reference bit: to track whether a page has been accessed
                <ul>
                  <li>used in page replacement</li>
                </ul>
              </li>
            </ul>
          </li>
          <li>Paging ‚Üí slow
            <ul>
              <li>the system must translate the virtual address</li>
              <li>Then, the hardware must be where the page table is for the currently running process</li>
              <li>Assume a single page-table base register contains the physical address of the starting location of the page table</li>
              <li>Paging requires extra memory access in order to first fetch the translation from the page table</li>
              <li>page tables will cause the system to run too slowly and take up too much memory.</li>
            </ul>
          </li>
          <li>Memory trace
            <ul>
              <li>The first instruction moves the value zero (shown as $0x0) into the virtual memory address of the location of the array;</li>
              <li>The second instruction increments the array index held in %eax, and the third instruction compares the contents of that register to the hex value 0x03e8, or decimal 1000.</li>
              <li>where in virtual memory the code snippet and array are found, as well as the contents and location of the page table.</li>
              <li>Let‚Äôs assume we have a linear (array-based) page table and that it is located at a physical address of 1 KB (1024)</li>
              <li>Worries
                <ul>
                  <li>First, there is the virtual page the code lives on. Because the page size is 1 KB, virtual address 1024 resides on the second page of the virtual address space</li>
                  <li>ts size is 4000 bytes (1000 integers), and it lives at virtual addresses 40000 through 44000 (not including the last byte). The virtual pages for this decimal range are VPN=39 ‚Ä¶ VPN=42. Thus, we need mappings for these pages.</li>
                </ul>
              </li>
              <li>When it runs, each instruction fetch will generate two memory references: one to the page table to find the physical frame that the instruction resides within, and one to the instruction itself to fetch it to the CPU for processing.</li>
              <li>one explicit memory reference in the form of the mov instruction; this adds another page table access first (to translate the array virtual address to the correct physical one) and then the array access itself.</li>
              <li>Need to see the figure carefully
  -</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>]]></content><author><name>JSC</name><email>newwin0198@handong.ac.kr</email></author><category term="OS" /><category term="OS" /><summary type="html"><![CDATA[OS Ch.18]]></summary></entry><entry><title type="html">Operating Systems: Three Easy Pieces Ch. 17</title><link href="http://localhost:4000/recent/Chapter-17/" rel="alternate" type="text/html" title="Operating Systems: Three Easy Pieces Ch. 17" /><published>2023-04-20T00:00:00+09:00</published><updated>2023-04-20T00:00:00+09:00</updated><id>http://localhost:4000/recent/Chapter-17</id><content type="html" xml:base="http://localhost:4000/recent/Chapter-17/"><![CDATA[<p>Free-Space Management</p>

<p>When free-space management becomes more difficult is when the free space with user-level memory-allocation memory</p>

<ul>
  <li>Segmentation</li>
  <li>External Fragmentation</li>
  <li>Internal fragmentation
    <ul>
      <li>if an allocator hands out chunks of memory bigger than that requested, any unasked for (and thus unused) space in such a chunk</li>
    </ul>
  </li>
  <li>void pointer</li>
  <li>Low-level Mechanisms
    <ul>
      <li>Splitting and Coalescing
        <ul>
          <li>requesting more than space that is free will fail ‚Üí splitting</li>
          <li>will find a free chunk of memory that can satisfy request</li>
          <li>What if returned space is in the middle of heap?</li>
          <li>It may end up with divided arrays with continuous size</li>
        </ul>
      </li>
      <li>Tracking the size of allocated regions
        <ul>
          <li>header block</li>
          <li>Embedding Free list</li>
          <li>mmap</li>
          <li>Fragmented free spaces
            <ul>
              <li>go through the list and merge neighboring chunks</li>
            </ul>
          </li>
          <li>Heap can grow heap
            <ul>
              <li>OS finds free physical pages, maps them into the address space of the requesting process, then returns the value of the end of the new heap</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Strategies
    <ul>
      <li>Best fit ‚Üí search through the free list and find chunks of free memory that bigger than the request size then return one that is the smallest in that group of candidate</li>
      <li>Worst fit ‚Üí case find the largest chunk and return the requested amount</li>
      <li>First fit ‚Üí finds the first block that is big enough and returns the requested amount to the user
        <ul>
          <li>May pollute the beginning of the free list with a small objects</li>
          <li>address-based ordering ‚Üí keeping the list ordered by the address of free space</li>
        </ul>
      </li>
      <li>Net fit ‚Üí keeps an extra pointer to the location within the list where one was looking last
        <ul>
          <li>Spread the search for free space throughout the list more uniformly, thus avoiding splintering of the beginning of the list</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Segregated List
    <ul>
      <li>Slab allocator
        <ul>
          <li>The basic idea is simple: if a particular application has one (or a few) popular-sized requests that it makes, keep a separate list just to manage objects of that size</li>
        </ul>
      </li>
      <li>Slab allocator
        <ul>
          <li>Specifically, when the kernel boots up, it allocates a number of object caches for kernel objects that are likely to be requested frequently</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Buddy allocation
    <ul>
      <li>big space of size 2^N</li>
      <li>search for free space recursively divides free space by two until a block that is big enough to accommodate the request is found</li>
      <li>may suffer internal fragmentation</li>
      <li>When returning the 8KB block to the free list, the allocator checks whether the ‚Äúbuddy‚Äù 8KB is free; if so, it coalesces the two blocks into a 16KB block.</li>
    </ul>
  </li>
  <li>One major problem with many of the approaches described above is their lack of scaling.</li>
</ul>]]></content><author><name>JSC</name><email>newwin0198@handong.ac.kr</email></author><category term="OS" /><category term="OS" /><summary type="html"><![CDATA[OS Ch.17]]></summary></entry><entry><title type="html">InterProcess Communication</title><link href="http://localhost:4000/recent/IPC/" rel="alternate" type="text/html" title="InterProcess Communication" /><published>2023-04-15T00:00:00+09:00</published><updated>2023-04-15T00:00:00+09:00</updated><id>http://localhost:4000/recent/IPC</id><content type="html" xml:base="http://localhost:4000/recent/IPC/"><![CDATA[<p>Signal</p>

<ul>
  <li>There can be hardware interrupts, but software interrupts as well</li>
  <li>GNU signal can be a great reference.
    <ul>
      <li>Linux relies on GNU</li>
    </ul>
  </li>
  <li>Signal API ‚Üí type of interrupt, handler</li>
  <li>Signal1.c
    <ul>
      <li>function pointer ‚Üí address of the program</li>
      <li>handler has no return but one input value; signal input is given</li>
      <li>Check signal is whether Sigint</li>
      <li>ctrl + c ‚Üí now task to the program from the outside</li>
      <li>It changes the control flow of the operation</li>
    </ul>
  </li>
  <li>Signal2.c
    <ul>
      <li>Alarm signal</li>
      <li>need to handle regular alarm</li>
      <li>Timer interrupt occurs by a sec</li>
      <li>by signaling, preemption happens and context switch as well</li>
    </ul>
  </li>
  <li>Pipe1.c
    <ul>
      <li>Nonzero value ‚Üí error</li>
      <li>pipe is a kind of file
        <ul>
          <li>File is anything that can have stream of information</li>
        </ul>
      </li>
      <li>Parent and child has same file description information</li>
      <li>Pipe works for reading and writing</li>
      <li>If the value is broken, make to write remaining data (buffer)</li>
      <li>Writing behavior depends on OS/ return sent value, it is because it has limited space of buffer</li>
      <li>No more data comes to the pipe</li>
      <li>3 is reading pipe, 4 is writing pipe</li>
      <li>reading happens up to 31 characters</li>
      <li>Child and parent process</li>
      <li>Through using file, parent and child process exchange their data</li>
      <li>It is something shared exclusively
        <ul>
          <li>Doesn‚Äôt have global name to be not interrupted by other processes.</li>
          <li>For one to one communication</li>
        </ul>
      </li>
      <li>Unnamed pipe ‚Üí use to make communicate</li>
      <li>multiple process invoked at same time, it is to difficult to clarify sender and messages
        <ul>
          <li>Synchronization</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Pipe2.c
    <ul>
      <li>duplicate operation</li>
      <li>hello program is loaded</li>
      <li>standard ouput goes to the pipe</li>
      <li>Hello is executed, sent to the pipe and show up at the display</li>
      <li>invoke the program at the middle of the program</li>
      <li>Library ‚Üí popen (read how to utilizte the API)
        <ul>
          <li>File is pipe</li>
          <li>execution results is given to file actually</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>]]></content><author><name>JSC</name><email>newwin0198@handong.ac.kr</email></author><category term="OS" /><category term="OS" /><summary type="html"><![CDATA[IPC lectures from Prof.Hong]]></summary></entry><entry><title type="html">Paging &amp;amp; Segmentation</title><link href="http://localhost:4000/recent/Paging&Segmentation/" rel="alternate" type="text/html" title="Paging &amp;amp; Segmentation" /><published>2023-04-15T00:00:00+09:00</published><updated>2023-04-15T00:00:00+09:00</updated><id>http://localhost:4000/recent/Paging&amp;Segmentation</id><content type="html" xml:base="http://localhost:4000/recent/Paging&amp;Segmentation/"><![CDATA[<h2 id="created-by-chatgpt">Created by ChatGPT</h2>

<p>The main disadvantage of using segmentation in operating systems is the potential for fragmentation, which can occur in two forms: external fragmentation and internal fragmentation.</p>

<ol>
  <li>External Fragmentation: This occurs when the free memory in the system becomes scattered in small chunks, making it difficult to allocate contiguous blocks of memory to satisfy larger memory requests. As a result, even though the total free memory may be sufficient, it may not be available in a contiguous block, leading to inefficient memory utilization.</li>
  <li>Internal Fragmentation: This occurs when allocated memory segments are larger than what the process actually needs, resulting in wasted memory space within a segment. This can happen when segments are allocated in fixed sizes, and a process does not fully utilize the entire segment, leaving unused memory within the segment.</li>
</ol>

<p>Both external and internal fragmentation can lead to reduced overall system performance and memory efficiency. Fragmentation can cause increased overhead in memory allocation and deallocation operations, as well as inefficient use of memory resources, which can result in decreased system performance and wasted memory.</p>

<p>Additionally, segmentation can also increase the complexity of memory management algorithms and may require additional hardware support, such as hardware-based address translation or segment table management, which can add overhead and increase system complexity.</p>

<p>In contrast, other memory management techniques, such as paging, which divides the memory into fixed-size blocks called pages, do not suffer from fragmentation issues. Paging allows for more efficient and flexible memory allocation and can provide better memory utilization compared to segmentation, particularly in large and complex systems.</p>

<p>Overall, the main disadvantage of using segmentation in operating systems is the potential for fragmentation, which can lead to reduced memory efficiency, increased overhead, and decreased system performance.</p>

<p>While paging as a memory management technique has several advantages, such as efficient memory utilization, simplified address translation, and ease of implementation, it also has some disadvantages. These disadvantages include:</p>

<ol>
  <li>Fragmentation within Pages: Paging can suffer from internal fragmentation, where the allocated memory within a page may not be fully utilized by a process. This occurs when the size of the page is larger than the actual memory requirements of the process, resulting in wasted memory space within a page. This can reduce overall memory efficiency and lead to increased memory overhead.</li>
  <li>Increased Page Table Size: Paging requires a page table to map virtual addresses to physical addresses. The size of the page table is directly proportional to the size of the virtual address space, which can be large for processes with a large address space. This can result in increased memory overhead, as the page table needs to be stored in memory and may consume a significant amount of memory space, especially in systems with multiple processes running concurrently.</li>
  <li>Overhead of Page Table Lookups: Paging introduces an additional step of address translation through the page table, which adds overhead to memory access times. This overhead can impact system performance, especially in systems with high levels of paging activity, where frequent page table lookups may result in increased CPU cycles and memory access times.</li>
  <li>Increased I/O Overhead: Paging can also result in increased I/O overhead, as pages may need to be loaded from secondary storage (such as disk) into physical memory when they are accessed for the first time, or when the system encounters a page fault. This can result in increased disk I/O operations, which may impact system performance and responsiveness.</li>
  <li>Limited Flexibility: Paging typically uses fixed-size pages, which may not always align well with the memory requirements of different processes. This can result in memory waste if a process needs a small amount of memory that is less than the page size. Additionally, if a process requires a larger memory allocation that spans multiple pages, it may result in increased overhead due to page table entries and additional address translation.</li>
</ol>

<p>Despite these disadvantages, paging remains a widely used and effective memory management technique in many operating systems due to its advantages in terms of memory utilization, address translation simplicity, and ease of implementation. However, addressing the limitations of paging, such as internal fragmentation and page table overhead, may require additional techniques such as page coloring, multi-level page tables, or hybrid approaches combining paging with other memory management techniques to optimize system performance and memory efficiency.</p>]]></content><author><name>JSC</name><email>newwin0198@handong.ac.kr</email></author><category term="OS" /><category term="OS" /><summary type="html"><![CDATA[Paging & Segmentation]]></summary></entry><entry><title type="html">Operating Systems: Three Easy Pieces Ch. 13</title><link href="http://localhost:4000/recent/Chapter-13/" rel="alternate" type="text/html" title="Operating Systems: Three Easy Pieces Ch. 13" /><published>2023-04-10T00:00:00+09:00</published><updated>2023-04-10T00:00:00+09:00</updated><id>http://localhost:4000/recent/Chapter-13</id><content type="html" xml:base="http://localhost:4000/recent/Chapter-13/"><![CDATA[<p>The abstraction: Address Space</p>

<ul>
  <li>Early Systems
    <ul>
      <li>OS was a set of routines that sat in memory</li>
      <li>Use the set of the memory</li>
      <li>Multiprogramming and Time Sharing
        <ul>
          <li>Multiprogramming</li>
          <li>Utilization</li>
          <li>Efficiency</li>
          <li>Time Sharing</li>
          <li>Interactivity</li>
          <li>Protection</li>
        </ul>
      </li>
      <li>The address space
        <ul>
          <li>easy to use abstract of physical memory</li>
          <li>code
            <ul>
              <li>have to live in memory somewhere</li>
            </ul>
          </li>
          <li>stack
            <ul>
              <li>keep track of where it is in the function call chain</li>
              <li>grow upward</li>
            </ul>
          </li>
          <li>heap
            <ul>
              <li>dynamic allocating memory</li>
              <li>grows downward</li>
            </ul>
          </li>
          <li>The whole thing is just a convention</li>
          <li>By putting stack and heap opposite, hopefully, grow well</li>
          <li>What if Multiple threads co-exists ‚Üí abstraction required</li>
        </ul>
      </li>
      <li>Virtualizing Memory
        <ul>
          <li>Transparency
            <ul>
              <li>Program should not be aware of the fact that memory is virtualized</li>
              <li>OS does works to multiplex memory</li>
            </ul>
          </li>
          <li>Efficiency
            <ul>
              <li>OS strive to make the virtualization as efficient as possible</li>
              <li>Both time and space</li>
              <li>rely on hardware</li>
            </ul>
          </li>
          <li>Protection
            <ul>
              <li>make sure to protect processes from one another as well as the OS itself from processes</li>
              <li>Property of isolation
  -</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>]]></content><author><name>JSC</name><email>newwin0198@handong.ac.kr</email></author><category term="OS" /><category term="OS" /><summary type="html"><![CDATA[OS Ch.13]]></summary></entry><entry><title type="html">Operating Systems: Three Easy Pieces Ch. 15</title><link href="http://localhost:4000/recent/Chapter-15/" rel="alternate" type="text/html" title="Operating Systems: Three Easy Pieces Ch. 15" /><published>2023-04-01T00:00:00+09:00</published><updated>2023-04-01T00:00:00+09:00</updated><id>http://localhost:4000/recent/Chapter-15</id><content type="html" xml:base="http://localhost:4000/recent/Chapter-15/"><![CDATA[<ul>
  <li>Limited Direct Execution (LDE)
    <ul>
      <li>Make the program run directly on the hardware</li>
      <li>OS gets involved and makes sure the ‚Äúright‚Äù thing happens</li>
      <li>Efficient virtualization, interposing at that critical point</li>
      <li>interposing at those critical point in the time, OS ensure that it maintains the control</li>
    </ul>
  </li>
  <li>Flexibility
    <ul>
      <li>we like for program to be able to use their address spaces in whatever way they would like</li>
    </ul>
  </li>
  <li>Address translation
    <ul>
      <li>Hardware-based address translation(address translation)
        <ul>
          <li>Virtual address provided by the instruction to a physical address where the desired location</li>
          <li>OS get involved at key points to set up hardware
            <ul>
              <li>Manage memory</li>
            </ul>
          </li>
          <li>Illusion of program has own memory, own code and own data</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Assumption
    <ul>
      <li>Small space</li>
      <li>less than size of physical memory, and all are in same size</li>
    </ul>
  </li>
  <li>Address space starts at address 0 and grows to a maximum of 16 KB</li>
  <li>relocate and transparent?</li>
  <li>Dynamic relocation
    <ul>
      <li>base and bound(limit) register as dynamic relocation</li>
      <li>Translation (Address translation)
        <ul>
          <li>Each memory reference generated by the process is a virtual address</li>
          <li>Hardware in turn adds the contents of the base register to this address</li>
          <li>Result is a physical address</li>
          <li>Due to relocationof the address happens at runtime, we can move address spaces even after the process started running ‚Üí dynamic relocation</li>
        </ul>
      </li>
      <li>Making sure memory reference is within bounds</li>
      <li>Memory management unit
        <ul>
          <li>size of the address space</li>
          <li>holds the physical address at the end of the address space</li>
        </ul>
      </li>
      <li>OS Issues
        <ul>
          <li>First, the OS must take actions when a process is created, finding space for its address space in memory</li>
          <li>Os will have to search a data structure(free list) to find room for new address space</li>
          <li>Taken actions when a process is terminated, reclaiming all of its memory for x</li>
          <li>Third, the OS must also be taken action when a context switch occurs and needs to save and restore the base-and-bound pairs when it switches between processes
            <ul>
              <li>It is privileged operations</li>
              <li>Required to access base-and-bounds registers; if a process, running in user mode, attempts to do so, the CPU will raise an exception and the OS will likely terminate the process</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Process Structure or Process Control Block</li>
      <li>Summary
        <ul>
          <li>Address translation</li>
          <li>Key to the efficiency of this technique is hardware support</li>
          <li>Transparent the process</li>
          <li>Base and bound register</li>
          <li>Protection</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>]]></content><author><name>JSC</name><email>newwin0198@handong.ac.kr</email></author><category term="OS" /><category term="OS" /><summary type="html"><![CDATA[OS Ch.15]]></summary></entry></feed>